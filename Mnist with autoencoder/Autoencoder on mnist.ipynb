{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "static-cleaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "comprehensive-involvement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ready-clarity",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext tensorboard\n",
    "#%tensorboard --logdir lightning_logs --port 6004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "polish-rating",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training and test datasets\n",
    "transform_train = transforms.Compose([\n",
    "    #transforms.RandomHorizontalFlip(),\n",
    "    #transforms.RandomCrop(size=32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5), (0.5)) #Normalize to (-1,1)\n",
    "])\n",
    "\n",
    "transform_eval = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5), (0.5)) #Normalize to (-1,1)\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='data', train=True,download=True, transform=transform_train)\n",
    "testset = torchvision.datasets.MNIST(root='data', train=False,download=True, transform=transform_eval)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sustained-instruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Dataloader\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "tribal-concentration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0\n",
      "Datatype of Image: <class 'torch.Tensor'>\n",
      "Shape of the Image: torch.Size([64, 1, 28, 28])\n",
      "Label Values: tensor([8, 1, 8, 3, 3, 3, 4, 1, 3, 2, 7, 8, 5, 6, 4, 1, 7, 9, 3, 3, 7, 1, 7, 0,\n",
      "        9, 9, 8, 2, 0, 7, 1, 7, 1, 3, 3, 7, 3, 7, 7, 0, 6, 9, 8, 0, 3, 0, 8, 7,\n",
      "        3, 4, 0, 4, 7, 1, 0, 8, 7, 4, 9, 4, 8, 8, 6, 0])\n"
     ]
    }
   ],
   "source": [
    "# We can use the exact same way to iterate over samples\n",
    "for i, item in enumerate(trainloader):\n",
    "    print('Batch {}'.format(i))\n",
    "    image, label = item\n",
    "    print(f\"Datatype of Image: {type(image)}\")\n",
    "    print(f\"Shape of the Image: {image.shape}\")\n",
    "    print(f\"Label Values: {label}\")\n",
    "\n",
    "    if i+1 >= 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "referenced-halloween",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 242, 242)\n",
      "(242, 242, 3)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    print(npimg.shape)\n",
    "    print(np.transpose(npimg, (1, 2, 0)).shape)\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "    \n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "black-europe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 7)\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, 7),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "functional-nurse",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CNNAutoencoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-89a3d4be5ce7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCNNAutoencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#model = model.to(device)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'CNNAutoencoder' is not defined"
     ]
    }
   ],
   "source": [
    "model = CNNAutoencoder()\n",
    "#model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rising-fifth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.kaiming_uniform_(m.weight,nonlinearity='relu')\n",
    "        m.bias.data.fill_(0.01)\n",
    "        \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-skirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.MSELoss()\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "#optimizer = optim.Adam(model.parameters(),  lr=0.001, betas=(0.9, 0.999), eps=1e-08, amsgrad=False)\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                 lr=0.001, \n",
    "                                 weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-china",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialising the list for storing the loss and accuracy\n",
    "\n",
    "training_loss = 0.0\n",
    "\n",
    "for epoch in range(20):\n",
    "    #Iterating through the minibatches of the data\n",
    "    for i, data in enumerate(trainloader):\n",
    "        \n",
    "        # data is a tuple of (inputs, labels)\n",
    "        image,_ = data\n",
    "        #image = image.to(device)\n",
    "        #y = y.to(device)\n",
    "        \n",
    "        # Reset the parameter gradients  for the current  minibatch iteration \n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        reconstruction = model(image)             # Perform a forward pass on the network with inputs\n",
    "        loss = criterion(image, reconstruction) \n",
    "        loss.backward()             # Perform a backward pass to calculate the gradients\n",
    "        optimizer.step()            # Optimise the network parameters with calculated gradients\n",
    "        training_loss += loss.item()\n",
    "    \n",
    "    training_loss = training_loss/len(trainloader)\n",
    "    print('Epoch: {}'.format(epoch),'\\tTraining Loss: {:.4f}'.format(training_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-physics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets get batch of test images\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "output = model(images)                     # get sample outputs\n",
    "images = images.numpy()                    # prep images for display\n",
    "output = output.view(64, 1, 28, 28)# resizing output\n",
    "output = output.detach().numpy()           # use detach when it's an output that requires_grad\n",
    "\n",
    "# plot the first ten input images and then reconstructed images\n",
    "fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(25,4))\n",
    "# input images on top row, reconstructions on bottom\n",
    "for images, row in zip([images, output], axes):\n",
    "    for img, ax in zip(images, row):\n",
    "        ax.imshow(np.squeeze(img), cmap='gray')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-rwanda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-brooklyn",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
